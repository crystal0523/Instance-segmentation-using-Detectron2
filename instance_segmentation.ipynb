{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "instance_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1t8bA7tP5wuniO4xY12FqB99Ip8bWmH12",
      "authorship_tag": "ABX9TyM5ORKA2WA/rheG/Y1DKrgL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crystal0523/Instance-segmentation-using-Detectron2/blob/main/instance_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGJm_r4Hl923"
      },
      "source": [
        "#install packages\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html\n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwy48XYuorih",
        "outputId": "bc32b876-f13b-4385-b7bc-b8293d9789ec"
      },
      "source": [
        "import torch, torchvision\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import random\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "setup_logger()\n",
        "\n",
        "import itertools\n",
        "from itertools import groupby\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from pycocotools import mask as maskutil\n",
        "from pycocotools import mask as maskUtils\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "setup_logger()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.0+cu101 True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Logger detectron2 (DEBUG)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A_ZKZhSpxQX"
      },
      "source": [
        "# register training and test datasets to Detectron2\n",
        "DatasetCatalog.clear()\n",
        "register_coco_instances(\"train_pascal\", {}, \"/content/drive/My Drive/pascal_train.json\", \"/content/drive/My Drive/train_images\")\n",
        "register_coco_instances(\"test\", {}, \"/content/drive/My Drive/test.json\", \"/content/drive/My Drive/test_images\")\n",
        "\n",
        "# metadata\n",
        "train_metadata = MetadataCatalog.get(\"train_pascal\")\n",
        "test_metadata = MetadataCatalog.get(\"test\")\n",
        "\n",
        "# dataset dictionary\n",
        "train_dataset_dicts = DatasetCatalog.get(\"train_pascal\")\n",
        "test_dataset_dicts = DatasetCatalog.get(\"test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4IoLTyxtule"
      },
      "source": [
        "#show image\n",
        "for d in random.sample(train_dataset_dicts, 3):\n",
        "    image = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(image[:, :, ::-1], metadata=train_metadata, scale=0.5)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egr-ciZJt3WL"
      },
      "source": [
        "cfg = get_cfg()\n",
        "\n",
        "# load ImageNet pretrained weights\n",
        "\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "\n",
        "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "\n",
        "# load dataset\n",
        "cfg.DATASETS.TRAIN = (\"train_pascal\",)\n",
        "\n",
        "# parameters\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 30000                    \n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   \n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 20  \n",
        "cfg.OUTPUT_DIR = \"/content/drive/My Drive/output1\"\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume = False)\n",
        "trainer.train()     \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPWC1Q7kvqzr",
        "outputId": "f877edd9-f31e-4ed8-c0a6-e4c0d83b5dd8"
      },
      "source": [
        "cfg.OUTPUT_DIR = \"/content/drive/My Drive/output1\"\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (\"test\", )\n",
        "coco = COCO('/content/drive/My Drive/pascal_train.json') \n",
        "\n",
        "# save categories\n",
        "CLASS_NAMES = [coco.cats[k]['name'] for k in coco.cats.keys()]\n",
        "\n",
        "# metadata\n",
        "test_metadata.set(thing_classes=CLASS_NAMES)\n",
        "\n",
        "# define predictor\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.24s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mOoG8xaD1H-"
      },
      "source": [
        "# store testing results to json file\n",
        "def binary_mask_to_rle(binary_mask):\n",
        "    rle = {'counts': [], 'size': list(binary_mask.shape)}\n",
        "    counts = rle.get('counts')\n",
        "    for i, (value, elements) in enumerate(groupby(binary_mask.ravel(order='F'))):\n",
        "        if i == 0 and value == 1:\n",
        "            counts.append(0)\n",
        "        counts.append(len(list(elements)))\n",
        "    compressed_rle = maskutil.frPyObjects(rle, rle.get('size')[0], rle.get('size')[1])\n",
        "    compressed_rle['counts'] = str(compressed_rle['counts'], encoding='utf-8')\n",
        "    return compressed_rle\n",
        "\n",
        "# load test annotations\n",
        "cocoGt = COCO(\"/content/drive/My Drive/test.json\")\n",
        "\n",
        "# store results\n",
        "coco_dt = []\n",
        "\n",
        "for imgid in cocoGt.imgs:\n",
        "    # read test image\n",
        "    image = cv2.imread(\"/content/drive/My Drive/test_images/\" + cocoGt.loadImgs(ids=imgid)[0]['file_name'])[:,:,::-1]\n",
        "\n",
        "    # make prediction\n",
        "    outputs = predictor(image)\n",
        "\n",
        "    # parse prediction\n",
        "    boxes = (outputs['instances']._fields['pred_boxes'].tensor).cpu().numpy()\n",
        "    scores = (outputs['instances']._fields['scores']).cpu().numpy()\n",
        "    categories = (outputs['instances']._fields['pred_classes']).cpu().numpy()\n",
        "    masks = (outputs['instances']._fields['pred_masks']).cpu().numpy()\n",
        "    n_instances = len(scores)\n",
        "    if len(categories) > 0:\n",
        "        for i in range(n_instances):\n",
        "            pred = {}\n",
        "            pred['image_id'] = imgid\n",
        "            pred['score'] = float(scores[i])\n",
        "            pred['category_id'] = int(categories[i]) + 1\n",
        "            pred['segmentation'] = binary_mask_to_rle(masks[i,:,:])\n",
        "            \n",
        "            coco_dt.append(pred)\n",
        "with open('309551053.json', 'w') as f:\n",
        "    f.write(pd.Series(coco_dt).to_json(orient='values'))\n",
        "f.close()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuOafKrJILUM"
      },
      "source": [
        "# show several testing results\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/My Drive/output1/model_final.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6\n",
        "cfg.DATASETS.TEST = (\"test\")\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "for d in random.sample(test_dataset_dicts, 3):    \n",
        "    image = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(image)\n",
        "    v = Visualizer(image[:, :, ::-1],\n",
        "                   metadata=test_metadata, \n",
        "                   scale=0.8, \n",
        "                   instance_mode=ColorMode.IMAGE_BW  \n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dbnob__C4O9"
      },
      "source": [
        ""
      ]
    }
  ]
}